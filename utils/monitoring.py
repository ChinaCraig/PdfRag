"""
ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†ç³»ç»Ÿ
æ”¯æŒPrometheus + Grafanaé›†æˆ
"""
import time
import logging
import threading
from collections import defaultdict, deque
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import json
import os

logger = logging.getLogger(__name__)

@dataclass
class MetricPoint:
    """æŒ‡æ ‡æ•°æ®ç‚¹"""
    name: str
    value: float
    labels: Dict[str, str]
    timestamp: datetime
    
class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.metrics = defaultdict(deque)
        self.counters = defaultdict(float)
        self.gauges = defaultdict(float)
        self.histograms = defaultdict(list)
        self.timers = {}
        
        # ç³»ç»ŸæŒ‡æ ‡
        self.system_metrics = {
            'request_count': 0,
            'error_count': 0,
            'active_sessions': 0,
            'processing_files': 0,
            'db_connections': {
                'mysql': 0,
                'milvus': 0,
                'neo4j': 0
            }
        }
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = {
            'response_times': deque(maxlen=1000),
            'vector_search_times': deque(maxlen=1000),
            'graph_search_times': deque(maxlen=1000),
            'llm_call_times': deque(maxlen=1000),
            'file_processing_times': deque(maxlen=100)
        }
        
        # é”™è¯¯æŒ‡æ ‡
        self.error_metrics = {
            'milvus_errors': deque(maxlen=100),
            'neo4j_errors': deque(maxlen=100),
            'mysql_errors': deque(maxlen=100),
            'llm_errors': deque(maxlen=100),
            'processing_errors': deque(maxlen=100)
        }
        
        self._lock = threading.Lock()
        logger.info("æŒ‡æ ‡æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def increment_counter(self, name: str, value: float = 1.0, labels: Dict[str, str] = None):
        """å¢åŠ è®¡æ•°å™¨"""
        with self._lock:
            key = self._make_key(name, labels)
            self.counters[key] += value
            self._add_metric_point(name, value, labels or {})
    
    def set_gauge(self, name: str, value: float, labels: Dict[str, str] = None):
        """è®¾ç½®ä»ªè¡¨å€¼"""
        with self._lock:
            key = self._make_key(name, labels)
            self.gauges[key] = value
            self._add_metric_point(name, value, labels or {})
    
    def record_histogram(self, name: str, value: float, labels: Dict[str, str] = None):
        """è®°å½•ç›´æ–¹å›¾å€¼"""
        with self._lock:
            key = self._make_key(name, labels)
            self.histograms[key].append(value)
            # ä¿æŒæœ€è¿‘1000ä¸ªå€¼
            if len(self.histograms[key]) > 1000:
                self.histograms[key] = self.histograms[key][-1000:]
            self._add_metric_point(name, value, labels or {})
    
    def start_timer(self, name: str) -> str:
        """å¼€å§‹è®¡æ—¶"""
        timer_id = f"{name}_{time.time()}"
        self.timers[timer_id] = time.time()
        return timer_id
    
    def end_timer(self, timer_id: str, labels: Dict[str, str] = None) -> float:
        """ç»“æŸè®¡æ—¶"""
        if timer_id not in self.timers:
            return 0.0
        
        start_time = self.timers.pop(timer_id)
        duration = time.time() - start_time
        
        # æå–æŒ‡æ ‡åç§°
        name = timer_id.split('_')[0]
        self.record_histogram(f"{name}_duration", duration, labels)
        
        return duration
    
    def _make_key(self, name: str, labels: Dict[str, str] = None) -> str:
        """åˆ›å»ºæŒ‡æ ‡é”®"""
        if not labels:
            return name
        
        label_str = ','.join(f"{k}={v}" for k, v in sorted(labels.items()))
        return f"{name}{{{label_str}}}"
    
    def _add_metric_point(self, name: str, value: float, labels: Dict[str, str]):
        """æ·»åŠ æŒ‡æ ‡ç‚¹"""
        point = MetricPoint(
            name=name,
            value=value,
            labels=labels,
            timestamp=datetime.now()
        )
        
        self.metrics[name].append(point)
        # ä¿æŒæœ€è¿‘1000ä¸ªç‚¹
        if len(self.metrics[name]) > 1000:
            self.metrics[name].popleft()
    
    def get_metrics_summary(self, time_window: int = 300) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦ï¼ˆæœ€è¿‘Nç§’ï¼‰"""
        cutoff_time = datetime.now() - timedelta(seconds=time_window)
        summary = {}
        
        with self._lock:
            # è®¡æ•°å™¨
            summary['counters'] = dict(self.counters)
            
            # ä»ªè¡¨
            summary['gauges'] = dict(self.gauges)
            
            # ç›´æ–¹å›¾ç»Ÿè®¡
            summary['histograms'] = {}
            for key, values in self.histograms.items():
                if values:
                    summary['histograms'][key] = {
                        'count': len(values),
                        'avg': sum(values) / len(values),
                        'min': min(values),
                        'max': max(values),
                        'p50': self._percentile(values, 50),
                        'p90': self._percentile(values, 90),
                        'p95': self._percentile(values, 95),
                        'p99': self._percentile(values, 99)
                    }
            
            # æ—¶é—´åºåˆ—æŒ‡æ ‡
            summary['timeseries'] = {}
            for name, points in self.metrics.items():
                recent_points = [p for p in points if p.timestamp >= cutoff_time]
                if recent_points:
                    summary['timeseries'][name] = {
                        'count': len(recent_points),
                        'latest_value': recent_points[-1].value,
                        'avg_value': sum(p.value for p in recent_points) / len(recent_points)
                    }
        
        return summary
    
    def _percentile(self, values: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        sorted_values = sorted(values)
        k = (len(sorted_values) - 1) * percentile / 100
        f = int(k)
        c = k - f
        
        if f == len(sorted_values) - 1:
            return sorted_values[f]
        else:
            return sorted_values[f] * (1 - c) + sorted_values[f + 1] * c
    
    def export_prometheus_format(self) -> str:
        """å¯¼å‡ºPrometheusæ ¼å¼"""
        lines = []
        
        with self._lock:
            # è®¡æ•°å™¨
            for key, value in self.counters.items():
                lines.append(f"# TYPE {key.split('{')[0]} counter")
                lines.append(f"{key} {value}")
            
            # ä»ªè¡¨
            for key, value in self.gauges.items():
                lines.append(f"# TYPE {key.split('{')[0]} gauge")
                lines.append(f"{key} {value}")
            
            # ç›´æ–¹å›¾
            for key, values in self.histograms.items():
                if values:
                    base_name = key.split('{')[0]
                    labels_part = key[len(base_name):]
                    
                    # æ€»è®¡æ•°
                    lines.append(f"# TYPE {base_name} histogram")
                    lines.append(f"{base_name}_count{labels_part} {len(values)}")
                    
                    # æ€»å’Œ
                    lines.append(f"{base_name}_sum{labels_part} {sum(values)}")
                    
                    # åˆ†ä½æ•°æ¡¶
                    for percentile in [0.5, 0.9, 0.95, 0.99]:
                        p_value = self._percentile(values, int(percentile * 100))
                        lines.append(f"{base_name}_bucket{{le=\"{percentile}\"{labels_part[1:] if labels_part else ''}}} {p_value}")
        
        return '\n'.join(lines)

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
        self.active_requests = {}
        self._lock = threading.Lock()
    
    def start_request(self, request_id: str, request_type: str = "unknown"):
        """å¼€å§‹è¯·æ±‚ç›‘æ§"""
        with self._lock:
            self.active_requests[request_id] = {
                'type': request_type,
                'start_time': time.time(),
                'timer_id': self.collector.start_timer('request_duration')
            }
            
            self.collector.increment_counter('requests_total', labels={'type': request_type})
            self.collector.set_gauge('active_requests', len(self.active_requests))
    
    def end_request(self, request_id: str, success: bool = True, error_type: str = None):
        """ç»“æŸè¯·æ±‚ç›‘æ§"""
        with self._lock:
            if request_id not in self.active_requests:
                return
            
            req_info = self.active_requests.pop(request_id)
            duration = self.collector.end_timer(req_info['timer_id'], 
                                               labels={'type': req_info['type']})
            
            if success:
                self.collector.increment_counter('requests_success', 
                                                labels={'type': req_info['type']})
            else:
                self.collector.increment_counter('requests_error', 
                                                labels={'type': req_info['type'], 'error': error_type or 'unknown'})
            
            self.collector.set_gauge('active_requests', len(self.active_requests))
            self.collector.record_histogram('request_duration_seconds', duration,
                                          labels={'type': req_info['type']})

class DatabaseMonitor:
    """æ•°æ®åº“ç›‘æ§å™¨"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
    
    def record_query(self, db_type: str, operation: str, duration: float, success: bool = True):
        """è®°å½•æ•°æ®åº“æŸ¥è¯¢"""
        labels = {'db': db_type, 'operation': operation}
        
        self.collector.increment_counter('db_queries_total', labels=labels)
        self.collector.record_histogram('db_query_duration_seconds', duration, labels=labels)
        
        if success:
            self.collector.increment_counter('db_queries_success', labels=labels)
        else:
            self.collector.increment_counter('db_queries_error', labels=labels)
    
    def record_connection_status(self, db_type: str, active_connections: int):
        """è®°å½•è¿æ¥çŠ¶æ€"""
        self.collector.set_gauge('db_connections_active', active_connections, 
                                labels={'db': db_type})

class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
        self.alert_rules = []
        self.alert_history = deque(maxlen=1000)
        self.notification_handlers = []
    
    def add_alert_rule(self, name: str, condition: callable, severity: str = "warning"):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        self.alert_rules.append({
            'name': name,
            'condition': condition,
            'severity': severity
        })
    
    def add_notification_handler(self, handler: callable):
        """æ·»åŠ é€šçŸ¥å¤„ç†å™¨"""
        self.notification_handlers.append(handler)
    
    def check_alerts(self):
        """æ£€æŸ¥å‘Šè­¦"""
        current_metrics = self.collector.get_metrics_summary()
        
        for rule in self.alert_rules:
            try:
                if rule['condition'](current_metrics):
                    alert = {
                        'name': rule['name'],
                        'severity': rule['severity'],
                        'timestamp': datetime.now(),
                        'metrics': current_metrics
                    }
                    
                    self.alert_history.append(alert)
                    
                    # å‘é€é€šçŸ¥
                    for handler in self.notification_handlers:
                        try:
                            handler(alert)
                        except Exception as e:
                            logger.error(f"é€šçŸ¥å¤„ç†å™¨é”™è¯¯: {e}")
            
            except Exception as e:
                logger.error(f"å‘Šè­¦è§„åˆ™æ£€æŸ¥é”™è¯¯ {rule['name']}: {e}")

# å…¨å±€ç›‘æ§å®ä¾‹
metrics_collector = MetricsCollector()
performance_monitor = PerformanceMonitor(metrics_collector)
db_monitor = DatabaseMonitor(metrics_collector)
alert_manager = AlertManager(metrics_collector)

# è®¾ç½®é»˜è®¤å‘Šè­¦è§„åˆ™
def setup_default_alerts():
    """è®¾ç½®é»˜è®¤å‘Šè­¦è§„åˆ™"""
    
    # å“åº”æ—¶é—´è¿‡é•¿
    alert_manager.add_alert_rule(
        "é«˜å“åº”æ—¶é—´",
        lambda m: m.get('histograms', {}).get('request_duration', {}).get('p95', 0) > 10.0,
        "warning"
    )
    
    # é”™è¯¯ç‡è¿‡é«˜
    alert_manager.add_alert_rule(
        "é«˜é”™è¯¯ç‡",
        lambda m: (m.get('counters', {}).get('requests_error', 0) / 
                  max(m.get('counters', {}).get('requests_total', 1), 1)) > 0.1,
        "critical"
    )
    
    # æ•°æ®åº“è¿æ¥å¼‚å¸¸
    alert_manager.add_alert_rule(
        "æ•°æ®åº“è¿æ¥å¤±è´¥",
        lambda m: m.get('counters', {}).get('db_queries_error', 0) > 10,
        "critical"
    )

# æ—¥å¿—é€šçŸ¥å¤„ç†å™¨
def log_alert_handler(alert: Dict[str, Any]):
    """æ—¥å¿—å‘Šè­¦å¤„ç†å™¨"""
    logger.warning(f"ğŸš¨ å‘Šè­¦: {alert['name']} - {alert['severity']} - {alert['timestamp']}")

# ä¾¿æ·è£…é¥°å™¨
def monitor_function(func_name: str = None, db_type: str = None):
    """ç›‘æ§å‡½æ•°è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            name = func_name or func.__name__
            timer_id = metrics_collector.start_timer(name)
            
            try:
                result = func(*args, **kwargs)
                
                if db_type:
                    duration = metrics_collector.end_timer(timer_id, labels={'db': db_type})
                    db_monitor.record_query(db_type, name, duration, success=True)
                else:
                    metrics_collector.end_timer(timer_id)
                    metrics_collector.increment_counter(f'{name}_success')
                
                return result
                
            except Exception as e:
                if db_type:
                    duration = metrics_collector.end_timer(timer_id, labels={'db': db_type})
                    db_monitor.record_query(db_type, name, duration, success=False)
                else:
                    metrics_collector.end_timer(timer_id)
                    metrics_collector.increment_counter(f'{name}_error')
                
                raise
        
        return wrapper
    return decorator

# åˆå§‹åŒ–ç›‘æ§
def init_monitoring():
    """åˆå§‹åŒ–ç›‘æ§ç³»ç»Ÿ"""
    setup_default_alerts()
    alert_manager.add_notification_handler(log_alert_handler)
    logger.info("ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

# HTTPç«¯ç‚¹æ”¯æŒï¼ˆç”¨äºPrometheusæŠ“å–ï¼‰
def get_metrics_endpoint() -> str:
    """è·å–Prometheusæ ¼å¼çš„æŒ‡æ ‡"""
    return metrics_collector.export_prometheus_format()

def get_health_status() -> Dict[str, Any]:
    """è·å–å¥åº·çŠ¶æ€"""
    metrics = metrics_collector.get_metrics_summary()
    
    # ç®€å•çš„å¥åº·æ£€æŸ¥é€»è¾‘
    error_rate = (metrics.get('counters', {}).get('requests_error', 0) / 
                 max(metrics.get('counters', {}).get('requests_total', 1), 1))
    
    avg_response_time = metrics.get('histograms', {}).get('request_duration', {}).get('avg', 0)
    
    status = "healthy"
    if error_rate > 0.2:
        status = "unhealthy"
    elif error_rate > 0.1 or avg_response_time > 5.0:
        status = "degraded"
    
    return {
        "status": status,
        "error_rate": error_rate,
        "avg_response_time": avg_response_time,
        "active_requests": metrics.get('gauges', {}).get('active_requests', 0),
        "timestamp": datetime.now().isoformat()
    }